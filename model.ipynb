{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All directory paths are defined at the beginning of the code, making it easier to manage and modify paths if the data location changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths for the label files for 2022 and 2023 datasets.\n",
    "# Modify these paths according to the location of your data files.\n",
    "base_dir_2022 = '2022/2022/DataPublication_final'\n",
    "base_dir_2023 = '2023/2023/DataPublication_final'\n",
    "base_dir_validation= '2023_validacion/2023'\n",
    "base_dir_test= 'Test'\n",
    "\n",
    "# Define paths for ground truth data.\n",
    "labels_path_2022 = os.path.join(base_dir_2022, 'GroundTruth/HYBRID_HIPS_V3.5_ALLPLOTS.csv')\n",
    "labels_path_2023 = os.path.join(base_dir_2023, 'GroundTruth/train_HIPS_HYBRIDS_2023_V2.3.csv')\n",
    "labels_path_validation= os.path.join(base_dir_validation, 'GroundTruth/val_HIPS_HYBRIDS_2023_V2.3.csv')\n",
    "labels_path_test= os.path.join(base_dir_test, 'GroundTruth/test_HIPS_HYBRIDS_2023_V2.3.csv')\n",
    "\n",
    "# Define paths for satellite and UAV images.\n",
    "satellite_dir_2022 = os.path.join(base_dir_2022, 'Satellite')\n",
    "uav_dir_2022 = os.path.join(base_dir_2022, 'UAV')\n",
    "satellite_dir_2023 = os.path.join(base_dir_2023, 'Satellite')\n",
    "satellite_dir_validation= os.path.join(base_dir_validation, 'Satellite')\n",
    "satellite_dir_test=os.path.join(base_dir_test,'Satellite')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we load and inspect the CSV files for the 2022 and 2023 maize yield trials.  After loading the data, we display the first few rows to verify the structure and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files containing the ground truth labels for 2022 and 2023 into pandas DataFrames.\n",
    "labels_df_2022 = pd.read_csv(labels_path_2022)\n",
    "labels_df_2023 = pd.read_csv(labels_path_2023)\n",
    "\n",
    "# Display the first few rows of the 2022 dataset to inspect its structure and content.\n",
    "print(\"Data from 2022:\")\n",
    "print(labels_df_2022.head())\n",
    "\n",
    "# Display the first few rows of the 2023 dataset to inspect its structure and content.\n",
    "print(\"\\nData from 2023:\")\n",
    "print(labels_df_2023.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section includes functions to load satellite and UAV images and to associate these images with yield data from the corresponding plots. The extract_images_and_yield function processes the label DataFrame, matches each plot with its corresponding images based on location, experiment, row, and range, and returns a DataFrame containing the paths to the images along with the yield data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to load a .tif satellite image using the rasterio library.\n",
    "def load_tif_image(image_path):\n",
    "    with rasterio.open(image_path) as src:\n",
    "        return src.read()\n",
    "# Function to load a UAV image using matplotlib's imread function.\n",
    "def load_uav_image(image_path):\n",
    "    return plt.imread(image_path)\n",
    "\n",
    "# Function to extract images and associated yield data based on the label DataFrame.\n",
    "def extract_images_and_yield(labels_df, satellite_paths, uav_paths=None):\n",
    "    data = []\n",
    "    \n",
    "    for idx, plot_data in labels_df.iterrows():\n",
    "        location = plot_data['location']\n",
    "        row = str(int(plot_data['row']))  # Ensure row number is an integer and convert to string\n",
    "        range_no = str(int(plot_data['range']))  # Ensure range number is an integer and convert to string\n",
    "        experiment = plot_data['experiment']\n",
    "        yield_per_acre = plot_data['yieldPerAcre']\n",
    "        \n",
    "        # Search for satellite images corresponding to the plot\n",
    "        for path in satellite_paths:\n",
    "            if location in path and f\"{experiment}_{range_no}_{row}\" in path:\n",
    "                image_data = load_tif_image(path)\n",
    "                data.append({\n",
    "                    'image_path': path,\n",
    "                    'yield_per_acre': yield_per_acre,\n",
    "                    'year': 2023 if '2023' in path else 2022\n",
    "                })\n",
    "        \n",
    "        # Search for UAV images (applicable only for 2022)\n",
    "        if uav_paths:\n",
    "            for path in uav_paths:\n",
    "                if location in path and f\"{experiment}_{range_no}_{row}\" in path:\n",
    "                    image_data = load_uav_image(path)\n",
    "                    data.append({\n",
    "                        'image_path': path,\n",
    "                        'yield_per_acre': yield_per_acre,\n",
    "                        'year': 2022\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The yield data is loaded, image paths are retrieved, and the data from both years is extracted and combined into a single dataset, ready for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the ground truth yield data for 2022 and 2023 from CSV files.\n",
    "print(\"Loading yield data...\")\n",
    "# We already loaded the CSV files containing the ground truth labels for 2022 and 2023 into pandas DataFrames.\n",
    "\n",
    "# Get paths to satellite and UAV images for 2022.\n",
    "print(\"Obtaining image paths for 2022...\")\n",
    "satellite_paths_2022 = [os.path.join(root, file) for root, _, files in os.walk(satellite_dir_2022) for file in files if file.endswith('.TIF')]\n",
    "uav_paths_2022 = [os.path.join(root, file) for root, _, files in os.walk(uav_dir_2022) for file in files if file.endswith('.PNG')]\n",
    "\n",
    "# Get paths to satellite images for 2023.\n",
    "print(\"Obtaining image paths for 2023...\")\n",
    "satellite_paths_2023 = [os.path.join(root, file) for root, _, files in os.walk(satellite_dir_2023) for file in files if file.endswith('.TIF')]\n",
    "\n",
    "# Extract and combine image and yield data for 2022.\n",
    "print(\"Extracting data for 2022...\")\n",
    "data_2022 = extract_images_and_yield(labels_df_2022, satellite_paths_2022, uav_paths_2022)\n",
    "print(f\"2022 data extracted: {len(data_2022)} records.\")\n",
    "\n",
    "# Extract and combine image and yield data for 2023.\n",
    "print(\"Extracting data for 2023...\")\n",
    "data_2023 = extract_images_and_yield(labels_df_2023, satellite_paths_2023)\n",
    "print(f\"2023 data extracted: {len(data_2023)} records.\")\n",
    "\n",
    "# Combine data from both years into a single DataFrame.\n",
    "print(\"Combining data from 2022 and 2023...\")\n",
    "combined_data = pd.concat([data_2022, data_2023], ignore_index=True)\n",
    "print(f\"Combined data: {len(combined_data)} total records.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section introduces a function to filter out rows with missing yield_per_acre values from the combined dataset. The function is then applied to ensure only complete records are kept for further analysis, with the total number of valid records printed afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter out rows with NaN values in the 'yield_per_acre' column.\n",
    "def filter_data_with_yield(data):\n",
    "    return data.dropna(subset=['yield_per_acre'])\n",
    "\n",
    "# Filter the combined dataset to remove records with NaN yield values.\n",
    "print(\"Filtering data to remove records with NaN yield values...\")\n",
    "filtered_data = filter_data_with_yield(combined_data)\n",
    "print(f\"Filtered data: {len(filtered_data)} records.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section separates the filtered dataset to include only satellite images, using a string filter on the image paths. The number of satellite image records is then printed to verify the separation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the filtered data to include only satellite images.\n",
    "satellite_data = filtered_data[filtered_data['image_path'].str.contains('Satellite')]\n",
    "\n",
    "# Check the number of records in the satellite dataset.\n",
    "print(f\"Total satellite images: {len(satellite_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code provides a function to display a random sample of image data, showing the image path, yield per acre, and year for each entry. By running this function on the satellite dataset, we can visually validate that the image paths are correctly associated with the corresponding yield data, helping ensure that the dataset is properly structured for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display a sample of image data, including the image path, yield per acre, and year.\n",
    "def show_sample_info(data, sample_size=5, title=\"Sample Data\"):\n",
    "    sample_data = data.sample(n=sample_size)\n",
    "    for index, row in sample_data.iterrows():\n",
    "        print(f\"{title} - Example {index + 1}:\")\n",
    "        print(f\"Image Path: {row['image_path']}\")\n",
    "        print(f\"Yield per Acre: {row['yield_per_acre']}\")\n",
    "        print(f\"Year: {row['year']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Display a sample of satellite data to verify that the image paths and yield data are correctly linked.\n",
    "print(\"\\nSatellite Data Sample:\")\n",
    "show_sample_info(satellite_data, title=\"Satellite Data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: You can skip this part and move directly to model training using the complete training data if you have access to it. This section is primarily for cases where only a single dataset is available, and it is necessary to create training, validation, and test sets from it.\n",
    "\n",
    "In this part of the notebook, we prepare the data for modeling by splitting the satellite data into training, validation, and test sets. This step allows us to train the initial version of the model and assess its performance, even when only the training dataset is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate the filtered data to include only satellite images.\n",
    "satellite_data = filtered_data[filtered_data['image_path'].str.contains('Satellite')]\n",
    "\n",
    "# Verify the number of satellite data records.\n",
    "print(f\"Total satellite data: {len(satellite_data)}\")\n",
    "\n",
    "# Function to split the dataset into training, validation, and test sets.\n",
    "def split_data(data, test_size=0.2, val_size=0.1):\n",
    "    train_data, test_data = train_test_split(data, test_size=test_size, random_state=42)\n",
    "    train_data, val_data = train_test_split(train_data, test_size=val_size / (1 - test_size), random_state=42)\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "# Split the satellite data into training, validation, and test sets.\n",
    "satellite_train, satellite_val, satellite_test = split_data(satellite_data)\n",
    "print(f\"Satellite data - Training: {len(satellite_train)}, Validation: {len(satellite_val)}, Test: {len(satellite_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code prepares and trains a Convolutional Neural Network (CNN) to predict maize yield from satellite images. The images are preprocessed by normalizing and resizing them, then fed into the model. \n",
    "\n",
    "The model is trained on the satellite training dataset, validated on the validation set, and finally evaluated on the test set to assess its performance. The Root Mean Squared Error (RMSE) metric is used to evaluate how well the model predicts the yield from the images.\n",
    "\n",
    "Note: If you have complete training data, you can skip the splitting step and proceed directly to training the model with the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess TIF images.\n",
    "def load_and_preprocess_tif(image_path):\n",
    "    with rasterio.open(image_path) as src:\n",
    "        image = src.read()\n",
    "        image = np.moveaxis(image, 0, -1)  # Move the band to the last dimension\n",
    "        image = np.array(image, dtype=np.float32)\n",
    "        image = (image - image.min()) / (image.max() - image.min())  # Normalize\n",
    "        image = tf.image.resize(image, [128, 128])  # Resize to 128x128\n",
    "    return image\n",
    "\n",
    "# Function to load images and associated yield labels.\n",
    "def load_images_and_labels(data):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for _, row in data.iterrows():\n",
    "        image = load_and_preprocess_tif(row['image_path'])\n",
    "        images.append(image)\n",
    "        labels.append(row['yield_per_acre'])\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Load and prepare the satellite image data.\n",
    "print(\"Loading and preparing satellite image data...\")\n",
    "satellite_train_imgs, satellite_train_labels = load_images_and_labels(satellite_train)\n",
    "satellite_val_imgs, satellite_val_labels = load_images_and_labels(satellite_val)\n",
    "satellite_test_imgs, satellite_test_labels = load_images_and_labels(satellite_test)\n",
    "\n",
    "# Function to define a CNN model for regression.\n",
    "def create_cnn_model(input_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1, activation='linear')  # Regression output for predicting yield\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CNN model for satellite images.\n",
    "input_shape = (128, 128, 6)  # 6 channels in TIF images\n",
    "satellite_cnn_model = create_cnn_model(input_shape)\n",
    "\n",
    "# Train the CNN model on satellite images.\n",
    "satellite_cnn_model.fit(satellite_train_imgs, satellite_train_labels, validation_data=(satellite_val_imgs, satellite_val_labels), epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the CNN model on the test set.\n",
    "test_loss, test_rmse = satellite_cnn_model.evaluate(satellite_test_imgs, satellite_test_labels)\n",
    "print(f\"RMSE on satellite test data: {test_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code section, we load and preprocess satellite images, handling any potential errors if images are missing. All available data (training, validation, and test trainings sets) is combined into one dataset for training the CNN model. The model is defined using a previously mentioned function, and it is trained on the entire dataset to leverage all available data for better model performance.\n",
    "\n",
    "Note: The functions load_and_preprocess_tif, load_images_and_labels, and create_cnn_model are used here as defined earlier, ensuring consistency and reusability of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the training, validation, and test datasets into one.\n",
    "all_data = pd.concat([satellite_train, satellite_val, satellite_test])\n",
    "all_images, all_labels = load_images_and_labels(all_data)\n",
    "\n",
    "# Create the CNN model for satellite images.\n",
    "input_shape = (128, 128, 6)  # 6 channels in TIF images\n",
    "satellite_cnn_model = create_cnn_model(input_shape)\n",
    "\n",
    "# Train the CNN model using the combined dataset.\n",
    "satellite_cnn_model.fit(all_images, all_labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we prepare the validation dataset by constructing image paths, loading and preprocessing the images, and making yield predictions using a previously trained CNN model. The predictions are then added to the original CSV file, which is saved with the updated yield predictions.\n",
    "\n",
    "This process is crucial for validating the model's performance on a separate validation dataset, ensuring the model generalizes well to unseen data. The final CSV contains both the original data and the predicted yield values for further analysis or comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to construct the image path based on CSV row data.\n",
    "def build_image_path(row, base_path):\n",
    "    location = row['location']\n",
    "    block = f\"TP{int(row['block'])}\"  # Assuming 'block' is a number converted to TP1, TP2, etc.\n",
    "    experiment = str(int(row['experiment']))\n",
    "    row_value = str(int(row['row']))\n",
    "    range_value = str(int(row['range']))\n",
    "\n",
    "    image_name = f\"{location}-{block}-{experiment}_{range_value}_{row_value}.TIF\"\n",
    "    image_path = os.path.join(base_path, block, image_name)\n",
    "    \n",
    "    # Print the constructed image path to verify it\n",
    "    print(f\"Constructed image path: {image_path}\")\n",
    "    \n",
    "    return image_path\n",
    "\n",
    "# Load the CSV containing validation data.\n",
    "csv_path = labels_path_validation # Update to correct CSV path\n",
    "csv_data = pd.read_csv(csv_path)\n",
    "\n",
    "# Base path where images are stored.\n",
    "base_image_path = satellite_dir_validation # Update to the correct base path\n",
    "\n",
    "# Filter the data to include only TP1, TP2, TP3 blocks.\n",
    "valid_blocks = ['TP1', 'TP2', 'TP3']\n",
    "csv_data = csv_data[csv_data['block'].apply(lambda x: f\"TP{int(x)}\" in valid_blocks)]\n",
    "\n",
    "# Prepare images and make predictions.\n",
    "predicciones = []\n",
    "for _, row in csv_data.iterrows():\n",
    "    image_path = build_image_path(row, base_image_path)\n",
    "    image = load_and_preprocess_tif(image_path)\n",
    "    if image is not None:\n",
    "        image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "        predicted_yield = satellite_cnn_model.predict(image)[0][0]  # Make the prediction\n",
    "        predicciones.append(predicted_yield)\n",
    "    else:\n",
    "        predicciones.append(np.nan)  # Handle missing image case\n",
    "\n",
    "# Update the CSV with predicted yield values.\n",
    "csv_data['yieldPerAcre'] = predicciones\n",
    "\n",
    "# Save the updated CSV.\n",
    "csv_data.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section prepares the test dataset by using previously defined functions to construct image paths, load and preprocess images, and make yield predictions using the trained CNN model. The predictions are then added to the original test CSV file, and the updated file is saved. This process is crucial for evaluating the model's performance on the test data and generating results that can be analyzed or submitted for further evaluation.\n",
    "\n",
    "Note: The functions build_image_path and load_and_preprocess_tif are reused as defined earlier, ensuring consistency and efficiency in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the CSV containing test data.\n",
    "csv_path = labels_path_test  # Update to the correct CSV path\n",
    "csv_data = pd.read_csv(csv_path)\n",
    "\n",
    "# Base path where images are stored.\n",
    "base_image_path = satellite_dir_test  # Update to the correct base path\n",
    "\n",
    "# Filter the data to include only TP1, TP2, TP3 blocks.\n",
    "valid_blocks = ['TP1', 'TP2', 'TP3']\n",
    "csv_data = csv_data[csv_data['block'].apply(lambda x: f\"TP{int(x)}\" in valid_blocks)]\n",
    "\n",
    "# Prepare images and make predictions.\n",
    "predicciones = []\n",
    "for _, row in csv_data.iterrows():\n",
    "    image_path = build_image_path(row, base_image_path)\n",
    "    image = load_and_preprocess_tif(image_path)\n",
    "    if image is not None:\n",
    "        image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "        predicted_yield = satellite_cnn_model.predict(image)[0][0]  # Make the prediction\n",
    "        predicciones.append(predicted_yield)\n",
    "    else:\n",
    "        predicciones.append(np.nan)  # Handle missing image case\n",
    "\n",
    "# Update the CSV with predicted yield values.\n",
    "csv_data['yieldPerAcre'] = predicciones\n",
    "\n",
    "# Save the updated CSV.\n",
    "csv_data.to_csv(csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
